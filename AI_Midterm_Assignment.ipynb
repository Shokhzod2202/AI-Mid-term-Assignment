{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNupIym2Ii9TMizLsMuOa4Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shokhzod2202/AI-Mid-term-Assignment/blob/main/AI_Midterm_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kLEQoPhrf-9J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Task 1: Data Simulation\n",
        "def generate_sequential_data(num_sequences, sequence_length, failure_probability):\n",
        "    data = []\n",
        "\n",
        "    for _ in range(num_sequences):\n",
        "        sequence = []\n",
        "        for _ in range(sequence_length):\n",
        "            if np.random.rand() < failure_probability:\n",
        "                # Simulate a failure event\n",
        "                temperature = np.random.uniform(80, 120)\n",
        "                vibration = np.random.uniform(1, 10)\n",
        "                belt_speed = np.random.uniform(1, 5)\n",
        "                label = 1  # Failure detected\n",
        "            else:\n",
        "                temperature = np.random.uniform(40, 80)\n",
        "                vibration = np.random.uniform(0.1, 1)\n",
        "                belt_speed = np.random.uniform(5, 10)\n",
        "                label = 0  # No failure\n",
        "\n",
        "            sequence.append([temperature, vibration, belt_speed, label])\n",
        "        data.append(sequence)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Data Preprocessing\n",
        "def preprocess_sequential_data(data):\n",
        "    # Flatten and convert data to a numpy array\n",
        "    flat_data = np.array(data)\n",
        "\n",
        "    # Extract features (X) and labels (y)\n",
        "    X = flat_data[:, :, :-1]  # All columns except the last one\n",
        "    y = flat_data[:, -1, -1]  # Last column\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def scale_data(X):\n",
        "    # Reshape the data to make it 2D\n",
        "    num_samples, sequence_length, num_features = X.shape\n",
        "    X_reshaped = X.reshape(num_samples * sequence_length, num_features)\n",
        "\n",
        "    # Use StandardScaler to scale the data\n",
        "    scaler = StandardScaler()\n",
        "    scaled_X = scaler.fit_transform(X_reshaped)\n",
        "\n",
        "    # Reshape it back to 3D\n",
        "    scaled_X = scaled_X.reshape(num_samples, sequence_length, num_features)\n",
        "\n",
        "    return scaled_X\n",
        "\n",
        "\n",
        "def split_data(X, y, test_size=0.2, random_state=42):\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "hG9J3lhlgI56"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3: LSTM Model\n",
        "def create_lstm_model(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(64, input_shape=input_shape, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def compile_model(model):\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "zLxM_eTWgZHy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4: Model Training\n",
        "def train_model(model, X_train, y_train, epochs=10, batch_size=32):\n",
        "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)"
      ],
      "metadata": {
        "id": "c1yFN4pDggaJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 5: Real-time Simulation\n",
        "def simulate_real_time_data():\n",
        "    # Simulate real-time data for conveyor belts\n",
        "    # You can use the generate_sequential_data function here for simulation\n",
        "\n",
        "    # Assuming real-time data comes as a list of sequences\n",
        "    real_time_data = generate_sequential_data(5, 10, 0.1)  # Example: 5 sequences, length 10, 10% failure\n",
        "\n",
        "    return real_time_data\n"
      ],
      "metadata": {
        "id": "eGrYIEXBgkYd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    # Task 1: Data Simulation\n",
        "    print(\"Task 1: Generating synthetic data for training...\")\n",
        "    data = generate_sequential_data(100, 50, 0.1)  # 100 sequences, length 50, 10% failure\n",
        "\n",
        "    # Task 2: Data Preprocessing\n",
        "    print(\"Task 2: Preprocessing the generated data...\")\n",
        "    X, y = preprocess_sequential_data(data)\n",
        "    scaled_X = scale_data(X)\n",
        "    X_train, X_test, y_train, y_test = split_data(scaled_X, y)\n",
        "\n",
        "    # Task 3: LSTM Model\n",
        "    print(\"Task 3: Creating and compiling the LSTM model...\")\n",
        "    model = create_lstm_model(X_train.shape[1:])\n",
        "    compile_model(model)\n",
        "\n",
        "    # Task 4: Model Training\n",
        "    print(\"Task 4: Training the LSTM model...\")\n",
        "    train_model(model, X_train, y_train, epochs=20, batch_size=32)\n",
        "\n",
        "    # Task 5: Real-time Simulation\n",
        "    print(\"Task 5: Simulating real-time data...\")\n",
        "    real_time_data = simulate_real_time_data()\n",
        "\n",
        "    # Predict using the trained model for each real-time sequence\n",
        "    for i, sequence in enumerate(real_time_data, start=1):\n",
        "        real_time_X, real_time_y = preprocess_sequential_data([sequence])\n",
        "        real_time_X = scale_data(real_time_X)\n",
        "\n",
        "        # Pad or truncate the sequence to match the model's input shape\n",
        "        real_time_X = pad_sequences(real_time_X, maxlen=50, dtype='float32', padding='post', truncating='post')\n",
        "\n",
        "        # Predict using the trained model\n",
        "        predictions = model.predict(real_time_X)\n",
        "\n",
        "        # Implement alerting logic based on predictions\n",
        "        if predictions[0] > 0.5:\n",
        "            print(f\"Alert {i}: Failure detected in a real-time sequence.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2ZZDiHfgs9J",
        "outputId": "4dd0243c-c260-41d9-bc62-8cbe1fc3baa5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1: Generating synthetic data for training...\n",
            "Task 2: Preprocessing the generated data...\n",
            "Task 3: Creating and compiling the LSTM model...\n",
            "Task 4: Training the LSTM model...\n",
            "Epoch 1/20\n",
            "3/3 [==============================] - 2s 23ms/step - loss: 0.6883 - accuracy: 0.5875\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.6570 - accuracy: 0.9000\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.6247 - accuracy: 0.9250\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.5925 - accuracy: 0.9125\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.5567 - accuracy: 0.9125\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.5073 - accuracy: 0.9125\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.4265 - accuracy: 0.9125\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3870 - accuracy: 0.9125\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3022 - accuracy: 0.9125\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.3184 - accuracy: 0.9125\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.3165 - accuracy: 0.9125\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.3021 - accuracy: 0.9125\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.2771 - accuracy: 0.9125\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.2870 - accuracy: 0.9125\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2736 - accuracy: 0.9125\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2708 - accuracy: 0.9125\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2658 - accuracy: 0.9125\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2586 - accuracy: 0.9125\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2740 - accuracy: 0.9125\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.2496 - accuracy: 0.9125\n",
            "Task 5: Simulating real-time data...\n",
            "1/1 [==============================] - 0s 170ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UcTUhNN_gwo8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}